---
title: Sentient AI
category: software
tags: machine learning
xposts:
  - label: Facebook
    url: https://www.facebook.com/harrislap/posts/pfbid02TisB3LHUj3452GzMERGoADa3EewbBpycqrxgxF5vRFxKb5bGr5ABsZYuG5G3jhbYl
---

As machine learning technology continues to push the boundaries of what we expect computers to be able to do, I think we'll see more conversation about what sentience means and whether we've built a "sentient AI."

I continue to think we're nowhere near this milestone, but I can understand why some people might look at LLMs (Large Language Models) like the one powering ChatGPT and say "hmmm that's starting to look kinda close." Here's one way I think about those claims:

LLMs and image generating models (like [DALL-E][], [Midjourney][], and [Stable Diffusion][]) use related approaches to 1. "predict" a way to complete a piece of text, in one case, or 2. derive an image that relates to a text prompt, in the other.

If [ChatGPT][] appears to be sentient to you, but [DALL-E][] does not, can you identify what the difference is?

To be clear, there *are* structural differences between LLMs and generative image models, and I'm not an expert on the specifics, though I've read a couple papers, but if someone is claiming one is sentient, I think they should be able to point at what differences make it so. So far I can't and I don't think "it generates words instead of pixels" is enough.

[DALL-E]: https://openai.com/dall-e-2
[Midjourney]: https://www.midjourney.com/
[Stable Diffusion]: https://stability.ai/stablediffusion
[ChatGPT]: https://openai.com/blog/chatgpt